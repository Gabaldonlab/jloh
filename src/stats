#!/usr/bin/env python3

"""
###
JLOH - Inferring Loss of Heterozygosity Blocks from Short-read sequencing data

Copyright (C) 2023 Matteo Schiavinato

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
###
"""



import argparse as ap
import sys
import pandas as pd
import numpy as np 
import multiprocessing as mp
from time import asctime as at
from operator import itemgetter

ss = sys.exit 

# help section
if len(sys.argv) == 1:
    sys.argv.append("--help")

if (sys.argv[1] in ["--help", "-h", "-help", "help", "getopt", "usage"]):
    sys.stderr.write("""

Calculate heterozygous and homozygous SNP density distributions from a VCF file

Usage:
jloh stats --vcf <VCF>

[I/O]

--vcf               Input VCF file to use for density calculations              [!]

[parameters]

--threads           Number of max. parallel operations                          [4]
--window-size       Size in bp to use for distribution                          [25000]
--step-size         Step size in bp for sliding window                          [5000]

""")
    sys.exit(0)


p = ap.ArgumentParser()
p.add_argument("--vcf")
p.add_argument("--threads", default=4, type=int)
p.add_argument("--window-size", default=25000, type=int)
p.add_argument("--step-size", default=5000, type=int)
args = p.parse_args()


# functions

def hetero_and_homo_snps(vcf):

    """
    Last update: 03/03/2022
    """

    # read SNPs
    INPUT = open(vcf, "r")
    Vcf_lines = [ line for line in INPUT if line[0] != "#" ]
    INPUT.close()

    Het_lines, Homo_lines = [],[]

    for line in Vcf_lines:

        # split by field
        lst = line.rstrip("\b\r\n").split("\t")

        # read values
        annotations = lst[8].split(":")
        values = lst[9].split(":")
        dict = { annotations[i]:values[i] for i in range(0, len(annotations)) }

        # Manage phased genotypes
        if dict["GT"][1] == "|":
            dict["GT"] = dict["GT"].replace("|", "/")

        # if it's a single heterozygous SNP
        if ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/1")):

            # 4. write out lines that have fitting values
            Het_lines.append(line)

        # if homozygous: keep for later assignment to blocks
        elif ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/0") \
        or (len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="1/1")):

            Homo_lines.append(line)

        # consider multiallelic sites
        # only if all alleles are SNPs
        # and if all alleles are not stars (spanning deletions)
        elif ((len(lst[3]) == 1) and (len(lst[4].split(",")) > 1)
        and (all([ len(x)==1 for x in lst[4].split(",") ])) \
        and (all([ x!="*" for x in lst[4].split(",") ]))):

            # this means that there are two annotations for AF
            # and that both have to be checked
            # so it is a variation on the previous block
            # which could be rendered into a function
            # assuming that there are > 1 AF annotation
            # splitting the field based on the comma
            # and converting to float the content
            AFs = [ float(x) for x in dict["AF"].split(",") ]

            # all it takes is one of the variants to be heterozygous
            # for the locus to be conserved
            # where het = AF comprised between --min-af and --max-af
            # 4. write out lines that have fitting values
            Het_lines.append(line)

    return Het_lines, Homo_lines


def get_chrom_lengths_from_vcf(vcf):

    """
    12/08/2022
    """

    IN = open(args.vcf, "r")
    Header = [line.rstrip("\r\b\n") for line in IN if line[0] == "#"]
    IN.close()

    Ctg_lines = [x.replace("##contig=<", "").replace(">", "") for x in Header if "##contig" in x]
    Ctg_lines = [x.split(",") for x in Ctg_lines]

    Chrom_lengths = {x[0].split("=")[1] : int(x[1].split("=")[1]) for x in Ctg_lines}
    return Chrom_lengths


def is_a_snp(line):

    """
    Last update: 03/03/2022
    """

    lst = line.rstrip("\r\b\n").split("\t")
    ref, alt = lst[3].split(","), lst[4].split(",")
    if (all([len(x)==1 for x in ref]) and all([len(y)==1 for y in alt])) == True:
        return True
    else:
        return False



def get_chrom_snps(args, chrom_snps, chrom, w_start, w_end, queue):

    """
    Last update: 23/10/2023 
    """

    w_snps = 0
    chrom_snps = [x for x in chrom_snps if x >= w_start]
    if len(chrom_snps) > 0:
        for var in chrom_snps:
            if (var < w_start):
                continue
            elif (w_start <= var <= w_end):
                w_snps+=1
            else:
                break
    else:
        w_snps = 0
    queue.put([chrom, w_start, w_snps])


def get_chrom_distances(chrom_snps, chrom, queue):

    """
    Last update: 23/08/2022
    """

    for snp in chrom_snps:
        idx = chrom_snps.index(snp)
        if idx > 0:
            d = chrom_snps[idx] - chrom_snps[idx-1]
            queue.put(d)


def calculate_chrom_snp_densities(Variants, Chrom_lengths, args):

    """
    Last update: 23/10/2023 
    """

    # extract SNPs and chromosome lengths
    # subdivide SNPs by chromosome
    Snps = [ (line.split("\t")[0], line) for line in Variants if is_a_snp(line) == True ]
    Snps_by_chrom = { chrom : [] for chrom in Chrom_lengths.keys() }

    for snp in Snps:
        Snps_by_chrom[snp[0]].append(int(snp[1].split("\t")[1]))

    queue = mp.Manager().Queue()
    pool = mp.Pool(args.threads)

    for chrom in Snps_by_chrom.keys():
        w_start = 0 
        w_end = w_start + args.window_size 
        chrom_snps = Snps_by_chrom[chrom]

        
        # while w_end < Chrom_lengths[chrom]:

        ### DEBUG ###
        while (w_end <= 700000):
        ### DEBUG ###
            pool.apply_async(get_chrom_snps, args=(args, chrom_snps, chrom, w_start, w_end, queue))
            w_start += args.step_size
            w_end += args.step_size    

    pool.close()
    pool.join()

    out = []
    while queue.qsize() > 0:
        x = queue.get()
        out.append(x)

    df = pd.DataFrame(out)
    df.columns = ["Chrom", "W_start", "Snps"]
    df = df.sort_values(by=["Chrom", "W_start"], ascending=[True, True])
    df = df.loc[df["Snps"] > 0 , :]
    df["Snps"] = (df["Snps"] / args.window_size * 1000).round(2)
    df = df.set_index(["Chrom", "W_start"])
    df_quant = df.quantile(q=list(np.arange(0,1,0.05)))
    df_quant = df_quant.reset_index(drop=False)
    df_quant = df_quant.rename({"index":"Quantile"}, axis=1)
    df_quant["Quantile"] = (df_quant["Quantile"] * 100).round(0).astype("int")

    return (df, df_quant)


def main(args):

    # split
    sys.stderr.write(f"[{at()}] Reading SNPs\n")
    Hetero_lines, Homo_lines = hetero_and_homo_snps(args.vcf)
    sys.stderr.write(f"[{at()}] found {len(Hetero_lines)} het SNPs and {len(Homo_lines)} homo SNPs\n")

    sys.stderr.write(f"[{at()}] Reading chrom lengths from VCF header\n")
    Chrom_lengths = get_chrom_lengths_from_vcf(args.vcf)
    sys.stderr.write(f"[{at()}] Read {len(Chrom_lengths.keys())} chromosome names and their lengths\n")
    All = Hetero_lines + Homo_lines

    # get densities
    sys.stderr.write(f"[{at()}] Calculating heterozygous SNP densities\n")
    Het, Het_quant = calculate_chrom_snp_densities(Hetero_lines, Chrom_lengths, args)
    sys.stderr.write(f"[{at()}] Calculating homozygous SNP densities\n")
    Homo, Homo_quant = calculate_chrom_snp_densities(Homo_lines, Chrom_lengths, args)
    sys.stderr.write(f"[{at()}] Combining to get general SNP densities\n")
    All, All_quant = calculate_chrom_snp_densities(All, Chrom_lengths, args)

    # unite them 
    df = All_quant.merge(Het_quant, on=["Quantile"]).merge(Homo_quant, on=["Quantile"])
    df.columns = ["Quantile", "Gen", "Het", "Homo"]
    Stats = df.loc[:,["Gen", "Het", "Homo"]].describe(include='float').round(2)

    all_mean = Stats.loc["mean", "Gen"]
    all_min = Stats.loc["min", "Gen"]
    all_max = Stats.loc["max", "Gen"]

    het_mean = Stats.loc["mean", "Het"]
    het_min = Stats.loc["min", "Het"]
    het_max = Stats.loc["max", "Het"]

    homo_mean = Stats.loc["mean", "Homo"]
    homo_min = Stats.loc["min", "Homo"]
    homo_max = Stats.loc["max", "Homo"]

    # 
    Out = [list(tup) for tup in df.itertuples()]
    Out = [(f" {x[1]}%", round(x[2], 2), round(x[3], 2), round(x[4], 2)) for x in Out]
    Out = ["\t".join([str(x) for x in lst]) for lst in Out]
    Out = [f" Q\tGen\tHet\tHomo"] + Out
    out_str = "\n".join(Out)

    # write to output
    sys.stderr.write(f"""

 -- SNPs/Kbp Statistics --

 S\tGen\tHet\tHomo
 Mean\t{all_mean}\t{het_mean}\t{homo_mean}
 Max\t{all_max}\t{het_max}\t{homo_max}
 Min\t{all_min}\t{het_min}\t{homo_min}

 -- SNPs/Kbp Quantiles --

{out_str}

 """)

if __name__ == "__main__":
    main(args)
